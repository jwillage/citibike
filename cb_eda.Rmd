---
title: "cb_eda"
author: "Joe Willage"
date: "November 18, 2015"
output: 
  html_document: 
    keep_md: yes
---

```{r setoptions, echo=FALSE, message=FALSE}
library(dplyr)
library(lubridate)
library(ggplot2)
library(knitr)

opts_chunk$set(echo = TRUE, cache = TRUE, cache.path = "cache/", 
               fig.path = "figure/", fig.width = 7, fig.height = 7)
```

Given a trip month file, explore some of the properties
```{r}
source("cb_analysis.R") 
distancePairs <- readRDS("data/distancePairs.rds") 
trip.month <- processMonthTrip("2013-10-01", distancePairs)
long <- which(trip.month$tripduration > 7200)
table(trip.month[long, ]$usertype) 
```

Surprisingly, we see that subscribers had bikes out for lengthy periods almost 
as much as customers. Perhaps this is due to the new-ness of the company, we
need to explore this for a later month file. 

Let's check out the remaining rows.

```{r}
trip.month <- trip.month[trip.month$tripduration < 7200, ]
g <- ggplot(trip.month, aes(x = tripduration/60))
g + geom_histogram(binwidth = 2, aes(fill = usertype)) + 
  facet_grid(. ~  usertype) + guides(fill = F)
```

Two things immediately jump out. First of all, there are a lot more subscriber 
trips than customers, in only the third month of the program. Unfortunately we 
don't have the data to compare unique riders. We can make a general assumption, 
like subscribers probably bike to work five days a week. Customers, on the other 
hand, we'll assume only make one round trip (two trips)  in a given month file. There are 
`r max(day(trip.month$starttime))` days in this file, 20 of them are working 
days (21 weekdays - 1 Labor Day holiday). So all things being even, we would 
expect 20 subscriber rides for every 2 customer rides, or 10 : 1. 

```{r}
users <- table(trip.month$usertype)
users["Customer"]
users["Subscriber"]/10
```

Although it appears from the histogram that there are many more subscribers than 
customers, under these assumptions, we see that
`r round(users["Customer"]/(users["Subscriber"]/10 + users["Customer"]) * 100, 2)`%
of this month's unique riders are customers. Since the types of users are not 
too different, we'll scale each plot's y-axis accordingly. We will split the 
plots on two rows, instead of the same row, to further emphasize the difference 
in scale. 

The second thing that jumps out in the histogram is the x-axis and all the 
seemingly blank space on the right hand side. We filtered on trips less than 120 
minutes, but there are still trips that take much longer than the median. 

```{r}
g <- ggplot(subset(trip.month, tripduration > 1800),
            aes(x = tripduration/60))
g + geom_histogram(binwidth = 2, aes(fill = usertype)) + 
  facet_wrap(~  usertype, scales = "free_y", nrow = 2) + guides(fill = F)
```

There are still thousands of trips in this tail that we don't want to ignore. 
Let's see how the log-transformed histogram of the original filtered data looks.

```{r}
g <- ggplot(trip.month, aes(x = log(tripduration/60)))
g + geom_histogram(aes(fill = usertype)) + 
  facet_wrap(~  usertype, scales = "free_y", nrow = 2) + guides(fill = F)
```

Pretty normal. We'll keep this in our back pocket in case it's needed later.

```{r}
subs <- trip.month$usertype == "Subscriber"
upper.bound.subs <- quantile(trip.month[subs, "tripduration"], .95)
upper.bound.cust <- quantile(trip.month[-subs, "tripduration"], .95)

```

In addition to taking 95%, we'll go back to plotting on the seconds scale rather
than minutes. Binwidths are 30 second intervals, giving us a pretty smooth 
curve. 

```{r}
trip.month <- trip.month %>% 
  mutate(inbounds = ifelse(usertype == "Customer", 
                           tripduration < upper.bound.cust , 
                           tripduration < upper.bound.subs)) %>%
  filter(inbounds == TRUE)

subs <- trip.month$usertype == "Subscriber"

g <- ggplot(trip.month, aes(x =tripduration))
g + geom_histogram(binwidth = 30, aes(fill = usertype)) + 
  facet_wrap(~  usertype, scales = "free_y", nrow = 2) + guides(fill = F)
```

Now that we've got a data set that makes sense, let's dig in further. 

```{r}
g <- ggplot(trip.month, aes(y =tripduration/60, x = usertype))
g + geom_boxplot(aes(fill = usertype)) + guides(fill = F)
```

Almost identical boxplots for both user types. 

```{r}
rbind(summary(trip.month[subs, "tripduration"]), 
      summary(trip.month[-subs, "tripduration"]))
```

Nary a difference. Let's finally look at the trip distance estimates.

```{r}
g <- ggplot(trip.month, aes(y = est.distance, x = usertype))
g + geom_boxplot(aes(fill = usertype)) + guides(fill = F)
```

Here again we can see there's barely a difference between user types. 

Let's shift focus and explore a more recent month. 
 

```{r echo = F, eval = F}
monthFile <- "2014-03-01" 
rec.trip.month <- processMonthTrip(monthFile, distancePairs)
summary(rec.trip.month)

all.stations <- unique(c(rec.trip.month$start.station.id, rec.trip.month$end.station.id))
unknown.indices <- which(!all.stations %in% distancePairs$start.station.id)
print(unknown <- all.stations[unknown.indices])
```

```{r echo = F, eval = F}
#calculate distance matrix for these missing values and append to distance.pairs

#need to put this in it's own function for anytime we want to add more station combinations
tmp <- getMonthData(monthFile)
start <- tmp[, 4:7, with = FALSE]
end <- tmp[, 8:11, with = FALSE]; names(end) <- names(start)
tmp.station <-  rbind(start, end)
unknown.full <- unique(tmp.station[tmp.station$`start station id` %in% unknown, ])
existing.full <- unique(distancePairs[, 1:4, with = FALSE])

startCombs <- as.data.table(levels(interaction(paste(unknown.full$'start station id', 
                               unknown.full$'start station name',
                               unknown.full$'start station latitude', 
                               unknown.full$'start station longitude',
                               sep = ";"),
            paste(existing.full$start.station.id,
                  existing.full$start.station.name,
                  existing.full$start.station.latitude,
                  existing.full$start.station.longitude,
                  sep = ";")
            , sep = ";"
            )))
endCombs <- as.data.table(levels(interaction(            
                paste(existing.full$start.station.id,
                  existing.full$start.station.name,
                  existing.full$start.station.latitude,
                  existing.full$start.station.longitude,
                  sep = ";"),
                  paste(unknown.full$'start station id', 
                               unknown.full$'start station name',
                               unknown.full$'start station latitude', 
                               unknown.full$'start station longitude',
                               sep = ";"),
                sep = ";"
            )))
# interaction between new station and new station
newCombs <- as.data.table(levels(interaction(paste(unknown.full$'start station id', 
                               unknown.full$'start station name',
                               unknown.full$'start station latitude', 
                               unknown.full$'start station longitude',
                               sep = ";"),
                               paste(unknown.full$'start station id', 
                               unknown.full$'start station name',
                               unknown.full$'start station latitude', 
                               unknown.full$'start station longitude',
                               sep = ";"), sep = ";")))

combs <- rbind(startCombs, endCombs, newCombs)
combs <- separate(combs, V1, c(names(tmp.station), 
                               sub('start', 'end', names(tmp.station))), 
                   sep = ";")
setnames(combs, make.names(names(combs)))

#now make the call to google api to get estimates
stationDistanceMatrix <- Vectorize(stationDistanceMatrix)
estimates <- t(with(combs, stationDistanceMatrix(start.station.latitude,
                                               start.station.longitude,
                                               end.station.latitude, 
                                               end.station.longitude)))
newDp <- cbind(combs, estimates)
names(newDp)[9:10] <- c("est.time", "est.distance")
distancePairs <- rbind(distancePairs, newDp)
distancePairs$est.time <- 60 * 
  as.numeric(sub(" min[s]*", "", distancePairs$est.time))
distancePairs$est.distance <- sub(" mi", "", distancePairs$est.distance)

#convert feet to mi
rows.ft <- grep("ft", distancePairs$est.distance)
distancePairs$est.distance[rows.ft] <- round(
  as.numeric(sub(" ft", "", distancePairs[rows.ft]$est.distance)) * 0.000189, 
  2)
distancePairs$est.distance <- as.numeric(distancePairs$est.distance)
saveRDS(distancePairs, file = "data/distancePairs.rds")
```


```{r}
monthFile <- "2015-05-01"
rec.trip.month <- processMonthTrip(monthFile, distancePairs)
summary (rec.trip.month) 
```

We can add new stations to remove the NA's

```{r, eval = F}
unknown <- findUnknownStations(monthFile, rec.trip.month, distancePairs)
newDP <- addStations(unknown, distancePairs)
distancePairs.old <- distancePairs #keep the old one for backup
distancePairs <- newDP
```

Station additions:

*  March 2014 added 491, 530  
*  March 2015 added 255  
*  July 2015 added 3180  
*  August 2015, 90 new stations were introduced. Including a temporary [ET Bike-In Movie Valet Station.](http://citibikeblog.tumblr.com/post/127176036862/et-the-extra-terrestrial-bike-in-movie)


```{r NAs removed}
rec.trip.month <- processMonthTrip(monthFile, distancePairs)
summary (rec.trip.month) 
```

Let's remove the person who had their bike out for 34 days, and any other suspiciously long trips. 

```{r tail}
tail(rec.trip.month[order(rec.trip.month$tripduration),]$tripduration, 100)
```

Even the 100th longest trip of this month is close to 2 days. But instead of using the 95th 
percentile as a cutoff point, let's see what we get at the 99th. It's 
`r quantile(rec.trip.month[, "tripduration"], .99)/60` minutes. I like that better than 95%; Not
only does it give us more data, it brings us out of 30-odd minute upper bound and into the 70's,
which isn't unreasonable since subscribers are alloted 45 minutes. An interesting note is that if we
did take the 95th percentile, that value for this month is 
`r quantile(rec.trip.month[, "tripduration"], .95)/60` minutes, which is actually longer than it was
in the early months of the program. 

Let's see how the average trip has changed throughout the course of the program. Here, we'll
take each month's data up to the 99th percentile. 

```{r process all months, results = "hide"}
start <- ymd("2013-07-01"); end <- ymd("2015-10-01")
months <- as.character(seq(start, end, by = "1 month"))
avgs.mat <- NULL
for (m in 1:length(months)){
  t <- processMonthTrip(months[m], distancePairs)
  #take up to the 99th quantile
  upper <- quantile(t$tripduration, .99)
  t <- subset(t, tripduration < upper)
  avgs.mat <- rbind(avgs.mat, cbind(mean(t$tripduration), mean(t$birth.year, na.rm = TRUE), 
                            mean(subset(t, gender != 0)$gender), mean(t$est.time),
                            mean(t$est.distance)))

}
avgs <- data.frame(as.Date(months), avgs.mat)
names(avgs) <- c("month", "mean.duration", "mean.birth", "mean.gender", "mean.est.time", 
                 "mean.est.dist")
```

```{r }
avgs
```

We're still missing values for the stations added in August 2015. Working from the opening of 
CitiBikes to July 2015 gives us 25 months of full data, and we'll download the data for the new 
stations later on. 

```{r}
avgs <- avgs[complete.cases(avgs),]
avgs$month_no <- as.numeric(row.names(avgs))
breaks <- seq(1, nrow(avgs), by = 6)
g <- ggplot(avgs, aes(x = month_no, y = mean.duration))
g + geom_point(size = 6, color = "black") + geom_point(size = 5, color = "dodgerblue1") +
  # geom_smooth(method = "lm", formula  = y~ns(x,df =5), se = FALSE, color = "black")
  geom_smooth(method = "lm", formula = y ~ sin(2*pi*x/12) + cos(2*pi*x/12), se = FALSE, 
              color = "black") + 
  scale_x_continuous(breaks = breaks, labels = avgs[breaks, "month"])
```

So there is a huge seasonal effect on ride duration, as might be expected. But setting that aside, 
it doesn't appear that the duration has changed much year over year (with only 2 years of data to 
look at). Let's regress out the seasonality and see what happens. 

```{r}
fit <- lm(mean.duration ~ sin(2 * pi * month_no/12) + cos(2 * pi * month_no/12), data = avgs)
g <- ggplot(data.frame(mean.duration = avgs$mean.duration, resid.duration = resid(fit)),
            aes(x=mean.duration, y=resid.duration))
g <- g + geom_point(size = 6, color = "black") + geom_point(size = 5, color = "red")
g2 <- ggplot(data.frame(month.no = avgs$month_no, resid.duration = resid(fit)), 
             aes(x = month.no, y = resid.duration))
g2 <- g2 + geom_point(size = 6, color = "black") + geom_point(size = 5, color = "lightblue")

par(mfrow = c(1, 2))
plot(avgs$mean.duration, resid(fit), pch = 21, cex = 2,  bg = "red")
plot(avgs$month_no, resid(fit), pch = 21, cex = 2,  bg = "lightblue")
```

There's no apparent pattern in the residuals, which is good. 

Taking a broader look at all the pairwise comparisons.

```{r pairs}
panel.cor <- function(x, y, digits=2, prefix="", cex.cor) 
{
    usr <- par("usr"); on.exit(par(usr)) 
    par(usr = c(0, 1, 0, 1)) 
    r <- abs(cor(x, y)) 
    txt <- format(c(r, 0.123456789), digits=digits)[1] 
    txt <- paste(prefix, txt, sep="") 
    if(missing(cex.cor)) cex <- 0.8/strwidth(txt) 
 
    test <- cor.test(x,y) 
    # borrowed from printCoefmat
    Signif <- symnum(test$p.value, corr = FALSE, na = FALSE, 
                  cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                  symbols = c("***", "**", "*", ".", " ")) 
 
    text(0.5, 0.5, txt, cex = cex * r) 
    text(.8, .8, Signif, cex=cex, col=2) 
}
pairs(month ~ ., data = avgs, upper.panel = panel.cor)
```

Ignoring the perfect correlation between month and month_no, we see strong correlation between 
mean duration and the estimated Google Maps means. That serves as a good sanity check: a correlation 
of `r round(cor(avgs$mean.duration, avgs$mean.est.time), 2)` between actual mean duration and the
estimated mean duration, and correlation of `r round(cor(avgs$mean.duration, avgs$mean.est.dist), 2)`
between the mean duration and the mean estimated distance. Of course, we want to truly confirm the
estimated durations to the actual, which will allow us to use the estimated distances later down the
line. We'll want to do this on a row-by-row bassis, not over each month's mean.  

We see a strong correlation of `r round(cor(avgs$mean.duration, avgs$mean.gender), 2)` between 
gender and duration, which seems interesting. Also, correlations of 
`r round(cor(avgs$mean.birth, avgs$mean.gender), 2)` between age and gender, and age and duration. 

We again see the sinusoidal pattern when looking at month by mean duration (and the estimates), but, 
oddly, gender and age as well.

Let's take a closer look at the relationship between gender and average duration. 
```{r}
g <- ggplot(data = avgs, aes(x = mean.gender, y = mean.duration))
g + geom_point(size = 6, color = "black") + geom_point(size = 5, color = "green") +
    geom_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "black")

fit <- lm(mean.duration ~ mean.gender, avgs)
print(s <- summary(fit))
```

The adjusted $R^2 = `r round(s$adj.r.squared, 4)`$, not super conclusive. While we do get
a significant p-value, the standard error of `r round(s$coef[2, 2], 2)` is very large. A better
analysis would be a t-test between each gender and their duration, before taking means. 